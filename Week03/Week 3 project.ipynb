{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b2c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3ca0e",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfa8abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>META</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>BRK-B</th>\n",
       "      <th>...</th>\n",
       "      <th>PNC</th>\n",
       "      <th>MDLZ</th>\n",
       "      <th>MO</th>\n",
       "      <th>ADI</th>\n",
       "      <th>GILD</th>\n",
       "      <th>LMT</th>\n",
       "      <th>SYK</th>\n",
       "      <th>GM</th>\n",
       "      <th>TFC</th>\n",
       "      <th>TJX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003269</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.018326</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>-0.015228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013455</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.005559</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>-0.015466</td>\n",
       "      <td>-0.023272</td>\n",
       "      <td>-0.004768</td>\n",
       "      <td>-0.008806</td>\n",
       "      <td>-0.009122</td>\n",
       "      <td>-0.010335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.023152</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.053291</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.015158</td>\n",
       "      <td>0.091812</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>-0.004082</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.052344</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>-0.012275</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.013237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001121</td>\n",
       "      <td>-0.001389</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.020181</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>-0.002429</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>-0.001389</td>\n",
       "      <td>-0.025983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021361</td>\n",
       "      <td>-0.021269</td>\n",
       "      <td>-0.029282</td>\n",
       "      <td>-0.021809</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>-0.037746</td>\n",
       "      <td>-0.037669</td>\n",
       "      <td>-0.040778</td>\n",
       "      <td>-0.075591</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>-0.046988</td>\n",
       "      <td>-0.009855</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>-0.030856</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>-0.033380</td>\n",
       "      <td>-0.028763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006475</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>-0.009631</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.022103</td>\n",
       "      <td>-0.016116</td>\n",
       "      <td>-0.013914</td>\n",
       "      <td>-0.007462</td>\n",
       "      <td>-0.035296</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-0.003916</td>\n",
       "      <td>-0.005942</td>\n",
       "      <td>-0.013674</td>\n",
       "      <td>-0.004506</td>\n",
       "      <td>-0.003677</td>\n",
       "      <td>0.015038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-0.010629</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>-0.023621</td>\n",
       "      <td>-0.084315</td>\n",
       "      <td>0.009083</td>\n",
       "      <td>-0.027474</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>-0.010742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>-0.011251</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.002677</td>\n",
       "      <td>0.038211</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.005954</td>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-0.006111</td>\n",
       "      <td>-0.017929</td>\n",
       "      <td>-0.006116</td>\n",
       "      <td>-0.011703</td>\n",
       "      <td>0.025161</td>\n",
       "      <td>-0.017942</td>\n",
       "      <td>-0.016632</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>-0.007102</td>\n",
       "      <td>0.022012</td>\n",
       "      <td>0.021826</td>\n",
       "      <td>-0.041181</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.004595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.046064</td>\n",
       "      <td>0.044167</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.051401</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.016473</td>\n",
       "      <td>-0.008518</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>-0.003618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-0.010935</td>\n",
       "      <td>-0.017653</td>\n",
       "      <td>-0.003102</td>\n",
       "      <td>-0.020174</td>\n",
       "      <td>0.022763</td>\n",
       "      <td>-0.076830</td>\n",
       "      <td>-0.074417</td>\n",
       "      <td>-0.042741</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.014346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008469</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.018009</td>\n",
       "      <td>-0.004416</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>-0.015391</td>\n",
       "      <td>0.009363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.008669</td>\n",
       "      <td>-0.006912</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>-0.018091</td>\n",
       "      <td>0.029957</td>\n",
       "      <td>-0.043876</td>\n",
       "      <td>-0.045400</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016588</td>\n",
       "      <td>-0.007717</td>\n",
       "      <td>-0.003656</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.016619</td>\n",
       "      <td>0.005603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SPY      AAPL      MSFT      AMZN      TSLA     GOOGL      GOOG  \\\n",
       "0   -0.003269  0.001423 -0.000136  0.012222  0.018326  0.009260  0.008723   \n",
       "1    0.016127  0.023152  0.018542  0.008658  0.053291  0.007987  0.008319   \n",
       "2    0.001121 -0.001389 -0.001167  0.010159  0.001041  0.008268  0.007784   \n",
       "3   -0.021361 -0.021269 -0.029282 -0.021809 -0.050943 -0.037746 -0.037669   \n",
       "4   -0.006475 -0.009356 -0.009631 -0.013262 -0.022103 -0.016116 -0.013914   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "244 -0.010629  0.024400 -0.023621 -0.084315  0.009083 -0.027474 -0.032904   \n",
       "245 -0.006111 -0.017929 -0.006116 -0.011703  0.025161 -0.017942 -0.016632   \n",
       "246  0.013079  0.019245  0.042022 -0.000685  0.010526  0.046064  0.044167   \n",
       "247 -0.010935 -0.017653 -0.003102 -0.020174  0.022763 -0.076830 -0.074417   \n",
       "248 -0.008669 -0.006912 -0.011660 -0.018091  0.029957 -0.043876 -0.045400   \n",
       "\n",
       "         META      NVDA     BRK-B  ...       PNC      MDLZ        MO  \\\n",
       "0   -0.008426  0.013278 -0.015228  ... -0.013455 -0.008396 -0.005559   \n",
       "1    0.015158  0.091812  0.006109  ...  0.012807 -0.004082  0.004592   \n",
       "2   -0.020181  0.000604 -0.001739  ...  0.006757 -0.002429  0.005763   \n",
       "3   -0.040778 -0.075591 -0.006653  ... -0.034949  0.005326  0.015017   \n",
       "4   -0.007462 -0.035296  0.003987  ... -0.000646 -0.000908  0.007203   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "244 -0.011866 -0.028053 -0.010742  ... -0.004694 -0.011251 -0.001277   \n",
       "245 -0.002520 -0.000521 -0.000259  ... -0.014451  0.003945  0.001066   \n",
       "246  0.029883  0.051401  0.014720  ... -0.000368 -0.016473 -0.008518   \n",
       "247 -0.042741  0.001443 -0.014346  ... -0.008469 -0.004456 -0.001289   \n",
       "248 -0.030039  0.005945 -0.004117  ... -0.016588 -0.007717 -0.003656   \n",
       "\n",
       "          ADI      GILD       LMT       SYK        GM       TFC       TJX  \n",
       "0    0.000520 -0.015466 -0.023272 -0.004768 -0.008806 -0.009122 -0.010335  \n",
       "1    0.052344  0.003600 -0.012275  0.033021  0.026240  0.028571  0.013237  \n",
       "2    0.038879  0.009294  0.012244  0.003363  0.015301 -0.001389 -0.025983  \n",
       "3   -0.046988 -0.009855  0.004833 -0.030856 -0.031925 -0.033380 -0.028763  \n",
       "4   -0.000436 -0.003916 -0.005942 -0.013674 -0.004506 -0.003677  0.015038  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "244 -0.002677  0.038211  0.004134  0.002336 -0.008916 -0.005954  0.001617  \n",
       "245 -0.007102  0.022012  0.021826 -0.041181  0.005106 -0.009782 -0.004595  \n",
       "246  0.019544 -0.003590 -0.001641  0.003573  0.001451  0.008669 -0.003618  \n",
       "247 -0.018009 -0.004416  0.002819 -0.015526  0.004106 -0.015391  0.009363  \n",
       "248  0.004275 -0.001634  0.000937 -0.014391  0.001443 -0.016619  0.005603  \n",
       "\n",
       "[249 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据并删除缺失值\n",
    "rets = pd.read_csv(\"DailyReturn.csv\")\n",
    "rets = rets.dropna(subset=['SPY'])\n",
    "rets = rets.iloc[:,1:]\n",
    "rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3261fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据类型转换\n",
    "for col in rets.columns:\n",
    "    if rets[col].dtype == 'object':\n",
    "        print(f\"Running {col}\")\n",
    "        rets[col] = rets[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610e3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指数加权协方差函数\n",
    "def ewCovar(x, lbda):\n",
    "    m, n = x.shape\n",
    "    w = (1 - lbda) * lbda ** np.arange(m)[::-1]\n",
    "    w /= w.sum()\n",
    "    xm = x - x.mean()\n",
    "    return np.cov(xm, aweights=w, rowvar=False)\n",
    "\n",
    "def ewCovar(x, lbda):\n",
    "    m, n = x.shape\n",
    "    w = np.empty(m)\n",
    "    \n",
    "    # Remove the mean from the series\n",
    "    xm = np.mean(x, axis=0)\n",
    "    x = (x - xm).values\n",
    "    \n",
    "    # Calculate weight. Realize we are going from oldest to newest\n",
    "    w = (1 - lbda) * lbda ** np.arange(m)[::-1]\n",
    "    \n",
    "    # Normalize weights to 1\n",
    "    w /= np.sum(w)\n",
    "    \n",
    "    w = w.reshape(-1, 1)\n",
    "    \n",
    "    # covariance[i,j] = (w * x.T) @ x\n",
    "    return (w * x).T @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bc36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 百分比解释函数\n",
    "def PCA_pctExplained(covar):\n",
    "    pca = PCA()\n",
    "    pca.fit(covar)\n",
    "    explained_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "    return explained_var\n",
    "\n",
    "# 手动计算\n",
    "# def PCA_pctExplained_manual(covar):\n",
    "#     # 计算特征值和特征向量\n",
    "#     eig_vals, eig_vecs = np.linalg.eig(covar)\n",
    "    \n",
    "#     # 对特征值进行降序排序\n",
    "#     eig_vals_sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "#     eig_vals_sorted = eig_vals[eig_vals_sorted_indices]\n",
    "    \n",
    "#     # 计算总的特征值\n",
    "#     total_eig_vals = sum(eig_vals_sorted)\n",
    "    \n",
    "#     # 计算每个主成分解释的方差百分比\n",
    "#     var_exp = [(i / total_eig_vals) for i in eig_vals_sorted]\n",
    "#     cum_var_exp = np.cumsum(var_exp)  # 累积方差百分比\n",
    "    \n",
    "#     return cum_var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1087e41c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m pctExplained \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lbda \u001b[38;5;129;01min\u001b[39;00m lbda_values:\n\u001b[1;32m----> 6\u001b[0m     covar \u001b[38;5;241m=\u001b[39m ewCovar(rets\u001b[38;5;241m.\u001b[39mvalues, lbda)\n\u001b[0;32m      7\u001b[0m     expl \u001b[38;5;241m=\u001b[39m PCA_pctExplained(covar)\n\u001b[0;32m      8\u001b[0m     pctExplained[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlbda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m expl[:rets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mewCovar\u001b[1;34m(x, lbda)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Remove the mean from the series\u001b[39;00m\n\u001b[0;32m     14\u001b[0m xm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m xm)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate weight. Realize we are going from oldest to newest\u001b[39;00m\n\u001b[0;32m     18\u001b[0m w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lbda) \u001b[38;5;241m*\u001b[39m lbda \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marange(m)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# 测试函数\n",
    "lbda_values = [0.75, 0.85, 0.90, 0.95, 0.99]\n",
    "pctExplained = pd.DataFrame()\n",
    "\n",
    "for lbda in lbda_values:\n",
    "    covar = ewCovar(rets.values, lbda)\n",
    "    expl = PCA_pctExplained(covar)\n",
    "    pctExplained[f\"lambda={lbda}\"] = expl[:rets.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643027a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pctExplained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘图\n",
    "plt.figure(figsize=(10, 6))\n",
    "for col in pctExplained.columns:\n",
    "    plt.plot(pctExplained.index + 1, pctExplained[col], label=col)\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"% Explained by EigenValue\")\n",
    "plt.xlabel(\"Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6fc6e",
   "metadata": {},
   "source": [
    "As lambda descreases, the percent explained by the first eigenvalues increases. This is because more weight is added to the more recent observations. The lower the lambda, the lower the rank of the matrix 意味着独立的col越少，能被PCA解释的越多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349a5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9064392",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26042ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_psd(a, epsilon=0.0):\n",
    "    n = a.shape[0]\n",
    "    invSD = None\n",
    "\n",
    "    # 如果 a 不是相关矩阵，则转换为相关矩阵\n",
    "    if not np.allclose(np.diag(a), 1):\n",
    "        invSD = np.diag(1.0 / np.sqrt(np.diag(a)))\n",
    "        a = np.dot(invSD, a).dot(invSD)\n",
    "\n",
    "    # 计算特征值和特征向量\n",
    "    vals, vecs = np.linalg.eigh(a)\n",
    "    \n",
    "    # 修正特征值\n",
    "    vals = np.maximum(vals, epsilon)\n",
    "    \n",
    "    # 计算 T\n",
    "    T = 1.0 / np.dot(vecs**2,vals)\n",
    "    T = np.diag(T)\n",
    "    \n",
    "    # 计算 l\n",
    "    l = np.diag(np.sqrt(vals))\n",
    "    \n",
    "    # 计算 B\n",
    "    B = T.dot(vecs).dot(l)\n",
    "    \n",
    "    # 计算近似 PSD 矩阵\n",
    "    a_psd = B.dot(B.T)\n",
    "    \n",
    "    # 如果之前转换了相关矩阵，则反转这个转换\n",
    "    if invSD is not None:\n",
    "        invSD = np.diag(1.0 / np.diag(invSD))\n",
    "        a_psd = invSD.dot(a_psd).dot(invSD)\n",
    "\n",
    "    return a_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0589d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chol_psd(root, a):\n",
    "    n = a.shape[0]  # 获取矩阵a的行数\n",
    "    root.fill(0)  # 将root矩阵初始化为全0矩阵\n",
    "\n",
    "    for j in range(n):  # 对于矩阵a的每一列进行循环\n",
    "        s = 0.0\n",
    "        if j > 0:  # 如果不是第一列，需要计算之前列的点积\n",
    "            s = np.dot(root[j, :j], root[j, :j])\n",
    "\n",
    "        temp = a[j, j] - s\n",
    "        if 0 >= temp >= -1e-8:  # 如果temp的值接近0，则设置为0\n",
    "            temp = 0.0\n",
    "        root[j, j] = np.sqrt(temp)\n",
    "\n",
    "        if root[j, j] == 0.0:  # 如果对角元素为0，即当前列全为0\n",
    "            root[(j+1):n,j] = 0.0\n",
    "        else:\n",
    "            ir = 1.0 / root[j, j]\n",
    "            for i in range(j+1, n):\n",
    "                s = np.dot(root[i, :j], root[j, :j].T)\n",
    "                root[i, j] = (a[i, j] - s) * ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def _getAplus(A):\n",
    "    vals, vecs = np.linalg.eigh(A)\n",
    "    vals = np.diag(np.maximum(vals, 0))\n",
    "    return np.dot(vecs, np.dot(vals, vecs.T))\n",
    "\n",
    "def _getPS(A, W):\n",
    "    W05 = np.sqrt(W)\n",
    "    iW05 = np.linalg.inv(W05)\n",
    "    return np.dot(iW05, np.dot(_getAplus(np.dot(W05, np.dot(A, W05))), iW05))\n",
    "\n",
    "def _getPu(A, W):\n",
    "    Aret = A.copy()\n",
    "    np.fill_diagonal(Aret, 1)\n",
    "    return Aret\n",
    "\n",
    "def wgtNorm(A, W):\n",
    "    W05 = np.sqrt(W)\n",
    "    WA = W05.dot(A).dot(W05)\n",
    "    W_norm = np.sum(WA**2)\n",
    "    return np.sum(W_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc means pearson correlation\n",
    "def higham_nearestPSD(pc, W=None, epsilon=1e-9, maxIter=100, tol=1e-9):\n",
    "    n = pc.shape[0]\n",
    "    if W is None:\n",
    "        W = np.diag(np.ones(n))\n",
    "    \n",
    "    Yk = pc.copy()\n",
    "    norml = np.inf\n",
    "    i = 1\n",
    "\n",
    "    while i <= maxIter:\n",
    "        Rk = Yk - deltaS if i > 1 else Yk\n",
    "        Xk = _getPS(Rk, W)\n",
    "        deltaS = Xk - Rk\n",
    "        Yk = _getPu(Xk, W)\n",
    "        norm = wgtNorm(Yk - pc, W)\n",
    "        minEigVal = np.min(np.real(np.linalg.eigvals(Yk)))\n",
    "\n",
    "        if abs(norm - norml) < tol and minEigVal > -epsilon:\n",
    "            break\n",
    "\n",
    "        norml = norm\n",
    "        i += 1\n",
    "\n",
    "    if i < maxIter:\n",
    "        print(\"Converged in {} iterations.\".format(i))\n",
    "    else:\n",
    "        print(\"Convergence failed after {} iterations\".format(i - 1))\n",
    "\n",
    "    return Yk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd9967a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_sigma(n):\n",
    "    sigma = np.full((n, n), 0.9)\n",
    "    np.fill_diagonal(sigma, 1.0)\n",
    "    sigma[1, 2] = sigma[2, 1] = 0.7357\n",
    "    return sigma\n",
    "\n",
    "def evaluate_methods(n):\n",
    "    sigma = generate_sigma(n)\n",
    "    W = np.eye(n)  # Identity matrix as weight\n",
    "\n",
    "    hpsd = higham_nearestPSD(sigma)\n",
    "    npsd = near_psd(sigma)\n",
    "\n",
    "    norm_hpsd = wgtNorm(hpsd - sigma, W)\n",
    "    norm_npsd = wgtNorm(npsd - sigma, W)\n",
    "\n",
    "    print(f\"n={n}\")\n",
    "    print(f\"Distance near_psd()={norm_npsd}\")\n",
    "    print(f\"Distance higham_nearestPSD()={norm_hpsd}\")\n",
    "\n",
    "    higham_time = timeit.timeit(lambda: higham_nearestPSD(sigma), number=10) / 10\n",
    "    near_psd_time = timeit.timeit(lambda: near_psd(sigma), number=10) / 10\n",
    "\n",
    "    print(f\"Higham Took: {higham_time} seconds\")\n",
    "    print(f\"Near_PSD Took: {near_psd_time} seconds\")\n",
    "\n",
    "evaluate_methods(500)\n",
    "evaluate_methods(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70f904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "575068ba",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "from scipy.stats import norm\n",
    "# from scipy.linalg import cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_normal(N, cov, mean=None, seed=1234):\n",
    "    n = cov.shape[0]\n",
    "    if cov.shape[1] != n:\n",
    "        raise ValueError(f\"Covariance matrix is not square ({n},{cov.shape[1]})\")\n",
    "\n",
    "    if mean is None:\n",
    "        mean = np.zeros(n)\n",
    "    elif mean.shape[0] != n:\n",
    "        raise ValueError(f\"Mean ({mean.shape[0]}) is not the size of cov ({n},{n})\")\n",
    "\n",
    "    # Take the root of the covariance matrix\n",
    "    l = np.zeros([n,n])\n",
    "    chol_psd(l, cov)  \n",
    "\n",
    "    # Generate needed random standard normals\n",
    "    npr.seed(seed)\n",
    "    out = npr.standard_normal((N, n))\n",
    "\n",
    "    # Apply the Cholesky root to the standard normals\n",
    "    out = np.dot(out, l.T)\n",
    "\n",
    "    # Add the mean\n",
    "    out += mean\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e54fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_pca(a, nsim, pctExp=1, mean=None, seed=1234):\n",
    "    n = a.shape[0]\n",
    "\n",
    "    if mean is None:\n",
    "        mean = np.zeros(n)\n",
    "    elif mean.shape[0] != n:\n",
    "        raise ValueError(f\"Mean size {mean.shape[0]} does not match covariance size {n}.\")\n",
    "\n",
    "    # Eigenvalue decomposition\n",
    "    vals, vecs = np.linalg.eigh(a)\n",
    "    vals = np.real(vals)\n",
    "    vecs = np.real(vecs)\n",
    "    # Sort eigenvalues and eigenvectors\n",
    "    idx = vals.argsort()[::-1]\n",
    "    vals = vals[idx]\n",
    "    vecs = vecs[:, idx]\n",
    "\n",
    "    # Calculate total variance\n",
    "    tv = np.sum(vals)\n",
    "\n",
    "    # Select principal components based on pctExp\n",
    "    cum_var_exp = np.cumsum(vals) / tv\n",
    "    if pctExp < 1:\n",
    "        n_components = np.searchsorted(cum_var_exp, pctExp) + 1 # 这个函数在cum_var_exp数组中查找pctExp应该插入的位置\n",
    "        vals = vals[:n_components]\n",
    "        vecs = vecs[:, :n_components]\n",
    "    else:\n",
    "        n_components = n\n",
    "    # Construct principal component matrix\n",
    "    B = vecs @ np.diag(np.sqrt(vals))\n",
    "\n",
    "    # Generate random samples\n",
    "    np.random.seed(seed)\n",
    "    r = np.random.randn(n_components, nsim)\n",
    "    out = (B @ r).T\n",
    "\n",
    "    # Add the mean\n",
    "    out += mean\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化协方差矩阵\n",
    "pearson_cov = np.cov(rets.T)\n",
    "pearson_std = np.sqrt(np.diag(pearson_cov))\n",
    "pearson_cor = np.corrcoef(rets.T)\n",
    "\n",
    "ewma_cov = ewCovar(rets.values, 0.97)\n",
    "ewma_std = np.sqrt(np.diag(ewma_cov))\n",
    "ewma_cor = np.diag(1 / ewma_std) @ ewma_cov @ np.diag(1 / ewma_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "matrixType = [\"EWMA\", \"EWMA_COR_PEARSON_STD\", \"PEARSON\", \"PEARSON_COR_EWMA_STD\"]\n",
    "simType = [\"Full\", \"PCA=1\", \"PCA=0.75\", \"PCA=0.5\"]\n",
    "\n",
    "# 变回了covariance\n",
    "matrix_lookup = {\n",
    "    \"EWMA\": ewma_cov,\n",
    "    \"EWMA_COR_PEARSON_STD\": np.diag(pearson_std) @ ewma_cor @ np.diag(pearson_std),\n",
    "    \"PEARSON\": pearson_cov,\n",
    "    \"PEARSON_COR_EWMA_STD\": np.diag(ewma_std) @ pearson_cor @ np.diag(ewma_std)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# 执行模拟\n",
    "for sim in simType:\n",
    "    for mat in matrixType:\n",
    "        c = matrix_lookup[mat]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if sim == \"Full\":\n",
    "            for _ in range(20):\n",
    "                s = simulate_normal(25000, c)\n",
    "        else:\n",
    "            pctExp = float(sim.split('=')[1])\n",
    "            for _ in range(20):\n",
    "                s = simulate_pca(c, 25000, pctExp=pctExp)\n",
    "\n",
    "        elapse = (time.time() - start_time) / 20\n",
    "        covar = np.cov(s.T)\n",
    "        norm = np.sum((covar - c) ** 2)\n",
    "\n",
    "        results.append({\n",
    "            \"Matrix\": mat,\n",
    "            \"Simulation\": sim,\n",
    "            \"Runtime\": elapse,\n",
    "            \"Norm\": norm\n",
    "        })\n",
    "\n",
    "out_table = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ff49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8659ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
